---
title: "Herramientas clave para el diseño y análisis de experimentos en R"
author: "Bogotá, Colombia - Abril, 2019"
date: "Día 2: Pruebas de hipótesis"
subtitle: EGAP - Learning Days
output:
  html_document:
    toc: true
    toc_float: true
---


#Hoy

* Pruebas de hipótesis
     + $t$-test
     + Randomization inference

#1. Pruebas de hipótesis

Vamos a usar un ejemplo de un experimento en donde asignamos a las personas aleatoriamente para que reciban un dispositivo de purificación de agua gratis. Estamos interesados en saber si este tratamiento (i.e., el dispositivo de saneamiento) reduce el número de días en que una persona está enferma en un año. 

Lo primero que necesitamos es crear los datos. Para el propósito del siguiente ejercicio, utilizaremos aleatorización completa.

+ Realizamos el experimentos en 10 municipios
+ En cada mpio, tomamos una muestra aleatoria de 60 personas

```{r, warning=FALSE,message=FALSE}

rm(list = ls())
library(estimatr) # robust regression

# 1. Make a dataset ----------------------------------------------------------

# We are going to look at the example of an experiment where people are randomly
# assigned to receive a free water sanitation device. We are interested in
# whether the treatment reduces the number of days in the year that the person 
# was sick. We will look at different ways the treatment can be assigned.

# We conduct a survey in 10 villages

(villages <- c("vill 01","vill 02","vill 03","vill 04","vill 05",
              "vill 06","vill 07","vill 08","vill 09","vill 10"))

# We randomly sample 60 people in each village

(samples <- c(60,60,60,60,60,
             60,60,60,60,60))

# So our total sample size, N, is 10 x 60, or the sum of our samples

(N <- sum(samples))

# Generate a unique number for each person in our total sample

(ID <- 1:N)

# Now let's generate a variable telling us what village each person came 
# from:

village <- rep(x = villages,    # Repeat the names of the villages
               times = samples) # 60 times for each village

# Let's look at the ID and village for each person:

head(cbind(ID,village),30)

# Now generate a variable that is 1 if the person is female, and 0 if male

(female <- rep(c(rep(1,30),rep(0,30)),10)) # 30 females in each village sample

# Let's now generate how many days in the year people would have been sick for
# if they did not receive the water sanitation device (negative binomial dist.). 

(days.sick.no.device <- rnbinom(n = N, mu = 10,size = 1) + 7)

# Let's also imagine that some villages are hit by 
# an outbreak of a virus that means people in those villages were all sick 
# 5 times more during the year under study.

# Define the effect of having an outbreak in your village:

(outbreak.effect <- 5)    # the effect is 5 days

# Let's randomly choose 3 of the 10 villages that were hit by the virus

(outbreak.villages <- sample(x = villages,size = 3))

# Add the effect to the people in those villages using an if / else function, 
# this is the 'control' potential outcome for the people in our experiment

(Y0 <- 
     ifelse(
          # Is the person's village in the outbreak list?
          test = village %in% outbreak.villages,    
          # If yes, then give that person the outbreak effect
          yes = days.sick.no.device + outbreak.effect,
          # If no, then don't increase the number of days they were sick
          no = days.sick.no.device + 0
     ))

# Now let's generate the treatment effects, but let's imagine that the treatment
# is less effective for men on average than it is for women.

# If a male receives the treatment, he gets sick 2 times fewer in a year

(effect.male <- -2) 

# If a female receives the treatment, she gets sick 7 times fewer in a year

(effect.female <- -7)

# We can use the ifelse() function again 

(Y1 <- 
     ifelse(
          # Is the person a female?
          test = female == 1,
          # If yes, then give that person the female effect
          yes = Y0 + effect.female,
          # If no, then give that person the male effect
          no = Y0 + effect.male
     ))

# Now we have our experimental dataset: 

data <- data.frame(
     ID = ID,
     village = village,
     female = female,
     Y0 = Y0,
     Y1 = Y1
)

head(data)

# 2. Complete Random Assignment ----------------------------------------------

# Imagine we only had 200 devices to assign to people. In this case, simple 
# random assignment would be inappropriate, as we are likely to assign too many 
# (or too few) people to treatment. 

# Complete random assignment lets us determine exactly how many people we want
# to assign to treatment before we run the randomization.

# Generate a list of 200 1's and 400 0's

(complete.ra <- c(rep(1,200),
                 rep(0,N-200)))

# And then scramble it randomly using sample()
set.seed(12345)

# Notice that the default is sampling without replacement
(complete.ra <- sample(complete.ra)) 

sum(complete.ra)

# Let's add it to the data

data$complete.ra <- complete.ra

head(data)

# And let's generate the outcome we would have observed under this assignment

data$complete.obs <- with(data,Y1*complete.ra+Y0*(1-complete.ra))

head(data)

```

Queremos explorar si el suministro de dispositivos reduce el número promedio de días en el año en que la persona estuvo enferma. Para hacer esto, queremos probar si el número promedio de días es más alto para el grupo de control que para el grupo de tratamiento.

Usando el vector de "aleatorización completa", primero necesitamos calcular el promedio en cada grupo para nuestro experimento. Ahora, necesitamos revelar los datos observados y luego calcular la diferencia de medias:

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60),warning=FALSE, message=FALSE}

av.treat <- mean(data$complete.obs[data$complete.ra==1]) 
av.control <- mean(data$complete.obs[data$complete.ra==0]) 
diff.mean<- av.treat-av.control 
diff.mean
```

>¿Cómo podemos definir una prueba en este contexto?

Notemos que si nuestro tratamiento no tuviera ningún efecto, entonces ambos promedios deberían ser los mismos. Por lo tanto, nuestra hipótesis nula ($H_0$) debe ser que la diferencia entre estas dos medias es igual a cero.

**NOTA:** En particular, queremos saber cuál es la probabilidad de obtener una diferencia de medias tan extrema como la que observamos en los datos (quizás en términos absolutos) si la hipótesis nula es verdadera, el *p*-valor.

Haremos esto de dos maneras: usando una prueba $t$ y usando la inferencia de aleatorización (*Randomization Inference*). Recuerde que estas pruebas usan diferentes HIPÓTESIS NULAS.

##*t*-test

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60),warning=FALSE, message=FALSE}

# a. Prueba - t 
##############################################################

# H0: Media(# de días para los tratados) - Mean(# de días para los control) = 0

# Creamos un vector con los individuos tratados:
treated <- data$complete.obs[data$complete.ra==1]
treated

# Y luego calculamos su varianza 
var1 <- sum((treated - mean(treated))^2) / (length(treated) - 1)
var1

# Y luego lo mismo para el grupo de control:
not_treated <- data$complete.obs[data$complete.ra==0]
not_treated

var0 <- sum((not_treated - mean(not_treated))^2) / (length(not_treated) - 1)
var0

# ya con esta información podemos calcular el error est. de la diferencia
# (vamos a verlo con más calma mañana)

estimated_se <- sqrt(var1/length(treated) + var0/length(not_treated))
estimated_se

# Estimamos nuestro estadístico t convirtiendo todo a unidades estándar:
t_stat <- ((av.treat-av.control) - 0) / estimated_se
t_stat

# Para poder usar la distribución Estudiante t correcta, necesitamos
# calcular los grados de libertad (Satterthwaite)
df <- (var1/length(treated) + var0/length(not_treated))^2 / 
           ((var1/length(treated))^2 / (length(treated) - 1) + 
           (var0/length(not_treated))^2 / (length(not_treated) - 1))
df

# Dónde cae nuestro estadístico t con respecto a la distribución t?
# Instalar ggplot2 si todavía no lo tienen. Un paquete muy útil para hacer gráficas
#install.packages("ggplot2")

library(ggplot2)

# Generar una sequencia de diferentes valores de x
x <- seq(-5, 5, len = 100)
# Elemento vacío para el diagrma
p <- qplot(x, geom = "blank") 
# Graficar la distribución Estudiante t con los parámetros que acabamos de estimar: 
# i)  df= grados de libertad (df)
# ii) ncp = parámetro de no-centralidad. Queremos que sea 0.
stat <- stat_function(fun=dt, args=list(df=df, ncp=0), col="black", size=1)
# Agregamos esta distribución al gráfico vacío y la diferencia de medias estimada: 
p + stat + geom_vline(xintercept = t_stat, col="red") 

# Ahora, queremos el p-valor. Para esto, usamos la CDF de la distribución 
?pt # para entender mejor lo que estamos haciendo

# Ahora, queremos una prueba de una o dos colas?

# Un p-valor de una cola: la distribución está centrada en 0 y t_stat <0.
# Esto significa que estamos buscando la probabilidad de que veamos 
# un t-stat al menos tan PEQUEÑO (en nuestro caso) como éste (cola inferior).

# P-valor de dos colas: aquí necesitaríamos el mismo número más la probabilidad 
# de que veamos un t-stat mayor o igual a:
-t_stat

# Primero, miremos cuál es la probabilidad de observar un estadístico t tan pequeño como
# el que observamos: 
pt(t_stat, df=df, ncp=0, lower.tail=TRUE)
# Ahora, necesitamos esa probabilidad más la prob. de la cola superior. Podemos hacer esto
# con una sola línea de código: 
2 * pt(abs(t_stat), df, lower.tail=F)

# También podemos hacer esto usando la función integrada de R (como en la diapositiva de Dan de esta mañana)
# que se llama t.test:
t.test(treated, not_treated, alternative="less") # una cola
t.test(treated, not_treated, alternative="two.sided") # dos colas

# Otra forma: También podemos estimar esto usando una regresión, 
# pero tenemos que corregir nuestros errores estándar para tener en 
# cuenta la posibilidad de diferentes varianzas entre el tratamiento y los grupos de control.

(lm_robust(complete.obs~complete.ra, data=data))

```

##Randomization Inference para la hipotesis estricta 

Recordemos que la hipótesis nula ESTRICTA (a.k.a., *Sharp Null*) en RI es: 
$$H_0: y_i(1) - y_i(0) = 0$$ 
para TODAS las unidades.

La 'sharp null' nos permite "observar" todos los resultados potenciales para todos los invidiuos (**bajo la hipótesis nula**). Entonces, podemos generar una distribución de todas las distintas diferencias de medias estimadas que observaríamos al replicar el experimento múltiple veces si la nula fuera CIERTA.

En general hay dos formas de hacer esto.
1. Producimos una matriz con todos los posibles vectores de asignación de tratamiento permutando el número total de observaciones tratadas y el número de observaciones (aleatorización completa).
2. Si el número real de permutaciones es muy grande, podemos en vez de eso replicar la asignación del tratamiento, muchas muchas veces (por ej., 10.000 veces) 

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60),warning=FALSE, message=FALSE}

choose(10,6)
choose(50,25)

# Dado que la verdadera matriz de permutación en nuestro ejemplo es muy grande,
choose(600,400)
# usamos el método 2): Replicamos la asignación (ALEATORIAMENTE) del tratamiento
# 10.000 veces y solo nos quedamos con los vectores únicos (porque se pueden repetir):
perm_matrix <- matrix(NA, 10000, 600)
for (i in 1:10000){
perm_matrix[i,] <- sample(data$complete.ra, 600, replace=F)
}
perm_matrix<-unique(perm_matrix)

# Noten que cada fila es un experimento
dim(perm_matrix)

# Ahora estimamos la diferencia de medias para cada posible aleatorización

# Podemos usar un loop para esto: 
rand_ate <- NA # Vector vacio para ir incluyendo los resultados
for (i in 1:nrow(perm_matrix)){ # para cada uno de los vectores de tratamiento "falsos"

  mean_treat <- mean(data$complete.obs[perm_matrix[i,]==1])
  
  mean_control <- mean(data$complete.obs[perm_matrix[i,]==0])
  
  # calculamos la diferencia de medias para esta aleatorización
  rand_ate[i] <- mean_treat - mean_control
  
}

summary(rand_ate) # vector de permuatación de diferencias

# Podemos hacer una gráfica para ver mejor los resultados:

hist(rand_ate, breaks=100, 
     main="Distribución de permutación",
     xlab= "Valor del estadístico de prueba (doms)",
     ylab = "Freq.", xlim=c(-5,5))
abline(v=diff.mean, lwd=3, col="slateblue")


# ¿Cómo calculamos los p-valores en este contexto?

# Una cola
sum(rand_ate<=diff.mean)/length(rand_ate)

# Dos colas
sum(abs(rand_ate)<=diff.mean)/length(rand_ate)

```

##Main Points to Remember About Hypothesis Testing

1. Hypothesis testing is a calculation of the probability that we can reject stated hypotheses about our treatment effect. This provides us with a means of characterizing our certainty that an estimated treatment effect approximates the true treatment effect.
2. The most common hypothesis that we test is the sharp null hypothesis, which states that the treatment had absolutely no effect on any individual unit. To test this hypothesis, we calculate the probability that we could have observed the treatment effect we did if the treatment in reality had no effect whatsoever. This probability is known as a p-value. For example, a p-value of .05 is interpreted as a 5\% chance that we could observe a treatment effect at least as large as the one we found if the treatment in fact had no effect.
3. It is conventional that p-values of .05 or lower are "significant". This is an arbitrary cutoff, but it is so widely used in statistics that any study that fails to recover a p-value of less than .1 will report that the treatment effect is null. Nonetheless, also make sure to interpret the substance and magnitude of the treatment effect, and avoid focusing solely on statistical significance.
4. Type I error is when you reject the null hypothesis when it is actually true. In other words, you conclude that the treatment did have an effect, when in reality, it did not. The significance level can also be interpreted as the probability that we are committing Type I error. (Type II error is when you accept the null hypothesis when it is actually false, in other words, you conclude a null effect when one actually existed.)
5. Randomization inference enables us to calculate what the observed treatment effect would have been in every possible randomization of the experiment if we hypothesize that no subject responded to the treatment (our null hypothesis). From this, we can calculate the probability that we would have observed our treatment effect if the true treatment effect was actually zero. If this is a very low probability, then we have more confidence in the significance of our findings from the single randomization we actually observed.

