---
title: "Herramientas clave para Diseños y Análisis de Investigación Experimental en R"
author: "Ciudad de Guatemala, Guatemala - agosto, 2017"
date: "Día 3: Pruebas de hipótesis y estimación"
output: html_document
subtitle: Taller EGAP - Convivimos
---


#Hoy

* Pruebas de hipótesis
     + Pruebas de hipótesis paramétricas
     + Inferencia de aleatorización (randomization inference)
* Estimación de los efectos     

#1. Pruebas de hipótesis

Vamos a utilizar los mismos datos creados para la clase de R sobre Alteatorización. Para el propósito del siguiente ejercicio, utilizaremos aleatorización completa.

## Pruebas paramétricas y no paramétricas

```{r,echo=FALSE,warning=FALSE,message=FALSE}

# Necesitamos ... (lo mismo de ayer, se acuerdan?)
rm(list = ls())
set.seed(12345)

villages <- c("vill 01","vill 02","vill 03","vill 04","vill 05",
              "vill 06","vill 07","vill 08","vill 09","vill 10")

samples <- c(60,60,60,60,60,
             60,60,60,60,60)

N <- sum(samples)
ID <- 1:N

village <- rep(x = villages, times = samples) 

female <- rep(c(rep(1,30),rep(0,30)),10)
days.sick.no.device <- rnbinom(n = N,mu = 10,size = 1) + 7

outbreak.effect <- 5
outbreak.villages <- sample(x = villages,size = 3)
Y0 <- ifelse(test = village %in% outbreak.villages,
             yes = days.sick.no.device + outbreak.effect,
             no = days.sick.no.device + 0)

effect.male <- -2
effect.female <- -7
Y1 <- ifelse(test = female == 1,yes = Y0 + effect.female, no = Y0 + effect.male)

data <- data.frame(
     ID = ID,
     village = village,
     female = female,
     Y0 = Y0,
     Y1 = Y1
)

complete.ra <- c(rep(1,200),
                 rep(0,N-200))

set.seed(12345)

complete.ra <- sample(complete.ra)

data$complete.ra <- complete.ra

data$complete.obs <- with(data,Y1*complete.ra+Y0*(1-complete.ra))

```

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60),warning=FALSE, message=FALSE}

# Prueba de hipótesis
##########################################################################

# Queremos explorar si el suministro de dispositivos reduce el número promedio de días 
# en el año en que la persona estuvo enferma. Para hacer esto, queremos probar 
# si el número promedio de días es más alto para el grupo de control que para el grupo de tratamiento.

# Usando el vector de aleatorización completa (que ayer discutimos), 
# primero necesitamos calcular el promedio en cada grupo para nuestro experimento:

# Ahora, necesitamos revelar los datos observados:

av.treat <- mean(data$complete.obs[data$complete.ra==1]) 
av.control <- mean(data$complete.obs[data$complete.ra==0]) 
diff.mean<- av.treat-av.control 

# ¿Cómo podemos definir una prueba en este contexto?
# 1. Notemos que si nuestro tratamiento no tuviera ningún efecto, 
# entonces ambos promedios deberían ser los mismos. 
# Por lo tanto, nuestra hipótesis nula (H0) debe ser que 
# la diferencia entre estas dos medias es igual a cero.

# NOTA: En particular, queremos saber cuál es la probabilidad 
# de obtener una diferencia de medias tan extrema como la que observamos 
# en los datos (quizás en términos absolutos) si la hipótesis nula 
# es verdadera, * el p-valor *.

# Haremos esto de dos maneras: usando una prueba t y usando la inferencia de aleatorización
# Recuerde que estas pruebas poseen diferentes HIPÓTESIS NULA.

# a. Prueba - t 
##############################################################

# H0: Media(# de días para los tratados) - Mean(# de días para los control) = 0

# Creamos un vector con los individuos tratados:
treated <- data$complete.obs[data$complete.ra==1]
treated

# Y luego calculamos su varianza 
var1 <- sum((treated - mean(treated))^2) / (length(treated) - 1)
var1

# Y luego lo mismo para el grupo de control:
not_treated <- data$complete.obs[data$complete.ra==0]
not_treated

var0 <- sum((not_treated - mean(not_treated))^2) / (length(not_treated) - 1)
var0

# ya con esta información podemos calcular el error est. de la diferencia
# (lo que vimos ahora con Dan)

estimated_se <- sqrt(var1/length(treated) + var0/length(not_treated))
estimated_se

# Estimamos nuestro estadístico t convirtiendo todo a unidades estándar:
t_stat <- ((av.treat-av.control) - 0) / estimated_se
t_stat

# Para poder usar la distribución Estudiante t correcta, necesitamos
# calcular los grados de libertad (Satterthwaite)
df <- (var1/length(treated) + var0/length(not_treated))^2 / 
           ((var1/length(treated))^2 / (length(treated) - 1) + 
           (var0/length(not_treated))^2 / (length(not_treated) - 1))
df

# Dónde cae nuestro estadístico t con respecto a la distribución t?
# Instalar ggplot2 si todavía no lo tienen. Un paquete "la ley" para hacer gráficas :) 
#install.packages("ggplot2")
library(ggplot2)

# Generar una sequencia de diferentes valores de x
x <- seq(-5, 5, len = 100)
# Elemento vacío para el diagrma
p <- qplot(x, geom = "blank") 
# Graficar la distribución Estudiante t con los parámetros que acabamos de estimar: 
# i)  df= grados de libertad (df)
# ii) ncp = parámetro de no-centralidad. Queremos que sea 0.
stat <- stat_function(fun=dt, args=list(df=df, ncp=0), col="black", size=1)
# Agregamos esta distribución al gráfico vacío y la diferencia de medias estimada: 
p + stat + geom_vline(xintercept = t_stat, col="red") 

# Ahora, queremos el p-valor. Para esto, usamos la CDF de la distribución 
?pt # para entender mejor lo que estamos haciendo

# Ahora, queremos una prueba de una o dos colas?

# Un p-valor de una cola: la distribución está centrada en 0 y t_stat <0.
# Esto significa que estamos buscando la probabilidad de que veamos 
# un t-stat al menos tan PEQUEÑO (en nuestro caso) como éste (cola inferior).

# P-valor de dos colas: aquí necesitaríamos el mismo número más la probabilidad 
# de que veamos un t-stat mayor o igual a:
-t_stat

# Primero, miremos cuál es la probabilidad de observar un estadístico t tan pequeño como
# el que observamos: 
pt(t_stat, df=df, ncp=0, lower.tail=TRUE)
# Ahora, necesitamos esa probabilidad más la prob. de la cola superior. Podemos hacer esto
# con una sola línea de código: 
2 * pt(abs(t_stat), df, lower.tail=F)

# También podemos hacer esto usando la función integrada de R (como en la diapositiva de Dan de esta mañana)
# que se llama t.test:
t.test(treated, not_treated, alternative="less") # una cola
t.test(treated, not_treated, alternative="two.sided") # dos colas

# Otra forma: También podemos estimar esto usando una regresión, 
# pero tenemos que corregir nuestros errores estándar para tener en 
# cuenta la posibilidad de diferentes varianzas entre el tratamiento y los grupos de control.
lm(complete.obs~complete.ra, data=data)

# b. Inferencia de aleatorización  
######################################################

# Recordemos que la hipótesis nula ESTRICTA en RI es: 
# H0: y_i(1) - y_i(0) = 0 para TODAS las unidades

# La nula estricta no permite "observar" todos los resultados potenciales para todos
# los invidiuos. Entonces, podemos generar una distribución de todas las distintas diferencias
# de medias estimadas que observaríamos al replicar el experimento múltiple veces si la nula fuera CIERTA.

# En general hay dos formas de hacer esto.
# 1) Producimos una matriz con todos los posibles vectores de asignación de tratamiento permutando
#    el número total de observaciones tratadas y el número de observaciones (aleatorización completa).
# 2) Si el número real de permutaciones es muy grande, podemos en vez de eso replicar la asignación 
#    del tratamiento, muchas muchas veces (por ej., 10.000 veces) 

choose(10,6)
choose(50,25)

# Dado que la verdadera matriz de permutación en nuestro ejemplo es muy grande,
choose(600,400)
# usamos el método 2): Replicamos la asignación (ALEATORIAMENTE) del tratamiento
# 10.000 veces y solo nos quedamos con los vectores únicos (porque se pueden repetir):
perm_matrix <- matrix(NA, 10000, 600)
for (i in 1:10000){
perm_matrix[i,] <- sample(data$complete.ra, 600, replace=F)
}
perm_matrix<-unique(perm_matrix)

# Noten que cada fila es un experimento
dim(perm_matrix)

# Ahora estimamos la diferencia de medias para cada posible aleatorización

# Podemos usar un loop para esto: 
rand_ate <- NA # Vector vacio para ir incluyendo los resultados
for (i in 1:nrow(perm_matrix)){ # para cada uno de los vectores de tratamiento "falsos"

  mean_treat <- mean(data$complete.obs[perm_matrix[i,]==1])
  
  mean_control <- mean(data$complete.obs[perm_matrix[i,]==0])
  
  # calculamos la diferencia de medias para esta aleatorización
  rand_ate[i] <- mean_treat - mean_control
  
}

summary(rand_ate) # vector de permuatación de diferencias

# Podemos hacer una gráfica para ver mejor los resultados:

hist(rand_ate, breaks=50, 
     main="Distribución de permutación",
     xlab= "Valor del estadístico de prueba",
     ylab = "Freq.", xlim=c(-5,5))
abline(v=diff.mean, lwd=3, col="slateblue")


# ¿Cómo calculamos los p-valores en este contexto?

# Una cola
sum(rand_ate<=diff.mean)/length(rand_ate)

# Dos colas
sum(abs(rand_ate)<=diff.mean)/length(rand_ate)

```

#2. Estimación de los efectos

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}

# Borrar la memoria de R (y apagar notación científica)
rm(list = ls())                        
options(scipen=999)

# Colocar semilla para poder replicar los resultados. Por ejemplo, usemos la fecha abril 20 de 2015.
set.seed(20150420)                     

# 2. Análisis usando datos simulados
##############################################################################
# Simulemos una base de datos de tamaño n

# Número de personas en el estudio
n  <- 10                          

# El efecto promedio del tratamiento (estamos fijándolo en 1) 
effect <- 1                       

# Generar aleatoriamente los puntajes de los exámenes de la gente si no son tratados 
Y0 <- rnorm(n)                     

# Generar aleatoriamente los puntajes de los exámenes de la gente si son tratados 
Y1 <- Y0 + effect + rnorm(n)       

# Asiganción Aleatoria completa de la mitad de la gente a tratamiento
X  <- sample(0:1, n, replace = TRUE) 

# Usar tratamiento para "revelar" Y1 o Y0
Y  <- Y0*(1-X) + Y1*X  

# Miremos la base de datos (primero)
data <- data.frame(Y0, Y1,  X, Y)
#View(data)
summary(data)

# Podemos graficar los resultados potenciales de control y tratamiento para cada individuo
par(mfrow=c(1,1))
plot(1:n, Y1, xlab = "unit", ylab= "Resultados Potenciales")
points(1:n, Y0, col = "red")
arrows(1:n, Y0, 1:n, Y1, col = ifelse(Y0<Y1, "red", "black"))

# ¡Estamos listos para la estimación!
# Calcular el puntaje promedio observado para los controles
av.cntrl <- mean(Y[X==0]) 
av.cntrl

# Calcular el puntaje promedio observado para los tratados
av.treat <- mean(Y[X==1]) 
av.treat

# Calcular el efecto promedio del tratamiento
est.effect <- av.treat-av.cntrl       
est.effect

# Calcular el efecto promedio del tratamiento usando regresión 
summary(lm(Y ~ X))    

# ¿Qué tan cerca estamos del verdadero efecto? (recuerden que lo habíamos fijado en 1)
mean(Y1-Y0)

# Ahora revisemos si el estimado es insesgado. Para hacer esto, debemos calcular cuál sería el estiamdo 
# a través de todas las posibles aleatorizaciones (inferencia aleatorizada) 

new.estimate = function(Y0, Y1, X){
  # Entrar data para Y0, Y1 y X, la función vuelve a aleatorizar y genera un estimado
  # del efecto promedio del tratamiento dada la nueva aleatorización
  x.new <- sample(X)
  y.new <- Y1*x.new + Y0*(1-x.new)
  est   <-  mean(y.new[x.new==1]) -   mean(y.new[x.new==0])
  return(est)
}

sims <- sapply(1:1000, function(i) new.estimate(Y0, Y1, X))
hist(sims)

# NOTAR que la estiamción depende mucho de la manera en que se llevó a cabo la aleatorización
# Algunas veces va a estar muy por encima del efecto real, otras veces muy abajo, pero en promedio debería 
# estar correcto.

```

## Principales puntos para recordar sobre las pruebas de hipótesis

1. La prueba de hipótesis es un cálculo de la probabilidad de que podamos rechazar las hipótesis que hacemos sobre nuestro efecto de tratamiento. Esto nos proporciona un medio para caracterizar nuestra certeza de que un efecto de tratamiento estimado se aproxima al verdadero efecto del tratamiento.
2. La hipótesis más común que probamos es la hipótesis nula estricta, que establece que el tratamiento no tuvo absolutamente ningún efecto en ninguna unidad individual. Para probar esta hipótesis, calculamos la probabilidad de que hubiéramos observadodo el efecto del tratamiento que vimos si el tratamiento en realidad no tuvo ningún efecto. Esta probabilidad se conoce como el $p$-valor. Por ejemplo, un $p$-valor de $0,05$ se interpreta como un 5\% de probabilidad de que pudiéramos observar un efecto de tratamiento al menos tan grande como el que encontramos si el tratamiento de hecho no tiene ningún efecto.
3. Es convencional que los $p$-valores de $0,05$ o menos sean "significativos". Este es un corte arbitrario, pero es tan ampliamente utilizado en las estadísticas que cualquier estudio que cualquier estudio que no logre obtener un $p$-valor por debajo de 0,1 reporátará que el efecto del tratamiento es nulo. Sin embargo, también asegúrese de interpretar la sustancia y la magnitud del efecto del tratamiento, y evitar centrarse únicamente en la significación estadística.
4. El error de tipo I es cuando se rechaza la hipótesis nula cuando es realmente verdadera. En otras palabras, se concluye que el tratamiento sí tuvo un efecto, cuando en realidad no lo hizo. El nivel de significación también puede ser interpretado como la probabilidad de que estamos cometiendo un error de Tipo I. (Tipo II error es cuando se acepta la hipótesis nula cuando es en realidad falsa, en otras palabras, se concluye un efecto nulo cuando uno realmente existió.)
5. La inferencia por aleatorización nos permite calcular cuál sería el efecto del tratamiento observado en cada posible aleatorización del experimento si se postula que ningún sujeto respondió al tratamiento (nuestra hipótesis nula estricta). A partir de esto, podemos calcular la probabilidad de que habríamos observado nuestro efecto de tratamiento si el verdadero efecto del tratamiento fuera realmente cero. Si esta es una probabilidad muy baja, entonces tenemos más confianza en la importancia de nuestros hallazgos de la aleatorización única que realmente observamos.

#2. Estimación de los efectos

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}

# Borrar la memoria de R
rm(list = ls())                        

# Colocar semilla para poder replicar los resultados. Por ejemplo, usemos la fecha abril 20 de 2015.
set.seed(20150420)                     

# 2. Análisis usando datos simulados
##############################################################################
# Simulemos una base de datos de tamaño n

# Número de personas en el estudio
n  <- 10                          

# El efecto promedio del tratamiento (estamos fijándolo en 1) 
effect <- 1                       

# Generar aleatoriamente los puntajes de los exámenes de la gente si no son tratados 
Y0 <- rnorm(n)                     

# Generar aleatoriamente los puntajes de los exámenes de la gente si son tratados 
Y1 <- Y0 + effect + rnorm(n)       

# Asiganción Aleatoria completa de la mitad de la gente a tratamiento
X  <- sample(0:1, n, replace = TRUE) 

# Usar tratamiento para "revelar" Y1 o Y0
Y  <- Y0*(1-X) + Y1*X  

# Miremos la base de datos (primero)
data <- data.frame(Y0, Y1,  X, Y)
#View(data)
summary(data)

# Podemos graficar los resultados potenciales de control y tratamiento para cada individuo
par(mfrow=c(1,1))
plot(1:n, Y1, xlab = "unit", ylab= "Resultados Potenciales")
points(1:n, Y0, col = "red")
arrows(1:n, Y0, 1:n, Y1, col = ifelse(Y0<Y1, "red", "black"))

# ¡Estamos listos para la estimación!
# Calcular el puntaje promedio observado para los controles
av.cntrl <- mean(Y[X==0]) 
av.cntrl

# Calcular el puntaje promedio observado para los tratados
av.treat <- mean(Y[X==1]) 
av.treat

# Calcular el efecto promedio del tratamiento
est.effect <- av.treat-av.cntrl       
est.effect

# Calcular el efecto promedio del tratamiento usando regresión 
summary(lm(Y ~ X))    

# ¿Qué tan cerca estamos del verdadero efecto? (recuerden que lo habíamos fijado en 1)
mean(Y1-Y0)

# Ahora revisemos si el estimado es insesgado. Para hacer esto, debemos calcular cuál sería el estiamdo 
# a través de todas las posibles aleatorizaciones (inferencia aleatorizada) 

new.estimate = function(Y0, Y1, X){
  # Entrar data para Y0, Y1 y X, la función vuelve a aleatorizar y genera un estimado
  # del efecto promedio del tratamiento dada la nueva aleatorización
  x.new <- sample(X)
  y.new <- Y1*x.new + Y0*(1-x.new)
  est   <-  mean(y.new[x.new==1]) -   mean(y.new[x.new==0])
  return(est)
}

sims <- sapply(1:1000, function(i) new.estimate(Y0, Y1, X))
hist(sims)

# NOTAR que la estiamción depende mucho de la manera en que se llevó a cabo la aleatorización
# Algunas veces va a estar muy por encima del efecto real, otras veces muy abajo, pero en promedio debería 
# estar correcto.

```


