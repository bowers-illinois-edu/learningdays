---
title: Introducing Counterfactual Causal Inference
author: Jake Bowers and EGAP Learning Days Instructors
institute: University of Illinois @ Urbana-Champaign among other affiliations
bibliography: ../../Research-Group-Bibliography/big.bib
date: 8 April 2019 --- Bogot√°
header-includes: \graphicspath{{.}{../images/}}
output:
  binb::metropolis:
    citation_package: natbib    
---

\newcommand{\bX}{\mathbf{X}}
\newcommand{\bZ}{\mathbf{Z}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}




```{r include=FALSE, cache=FALSE}
# Some customization.  You can alter or delete as desired (if you know what you are doing).
# knitr settings to control how R chunks work.
rm(list=ls())

require(knitr)

## This plus size="\\scriptsize" from https://stackoverflow.com/questions/26372138/beamer-presentation-rstudio-change-font-size-for-chunk

knitr::knit_hooks$set(mysize = function(before, options, envir) {
  if (before)
    return(options$size)
})

knit_hooks$set(plotdefault = function(before, options, envir) {
    if (before) par(mar = c(3, 3, .1, .1),oma=rep(0,4),mgp=c(1.5,.5,0))
})

opts_chunk$set(
  tidy=FALSE,     # display code as typed
  echo=TRUE,
  results='markup',
  strip.white=TRUE,
  fig.path='figs/fig',
  cache=FALSE,
  highlight=TRUE,
  width.cutoff=132,
  size='\\scriptsize',
  out.width='.8\\textwidth',
  fig.retina=FALSE,
  message=FALSE,
  comment=NA,
  mysize=TRUE,
  plotdefault=TRUE)

if(!file.exists('figs')) dir.create('figs')

options(digits=4,
	scipen=8,
	width=132
	)
```

# What might `cause` **mean**?: Definitions and Conceptualization

## Some of my recent causal questions

Did \href{https://youtu.be/RgYIGLNdy9I}{a new Hausa television station} in
northern Nigeria change attitudes about violence, the role of women in
society, or the role of youth in society?

\only<2>{
\centering \includegraphics[width=.7\textwidth]{Arewa_pic1.png}}

Will adding education counselors to public housing in the USA increase the
numbers of low income youth enrolled in post-secondary education (like
university) and receiving financial aid for their education?

\only<3>{
\centering \includegraphics[width=.4\textwidth]{hudamps.pdf}}

Did the UKIP (anti-immigrant) party in the UK influence how individuals
\textbf{see} the ethnic characteristics of their communities?

\only<4>{
\centering \includegraphics[width=.5\textwidth]{beslondonmaps.pdf}}


## What are we doing when we talk about causation?

I think that social scientists try to work collectively to **build evidence** for explanations. So: we make individual contributions, we try to persuade ourselves that we have learned something, we correct our past misunderstandings, etc.

Strong evidence persuades --- it is harder to argue against than weak evidence.

Randomized experiments, we'll show, are especially persuasive about explanations involving **cause** in very focused ways. 

"[The experimenter's] aim is to draw valid conclusions of _determinate precision and generality_ from the evidence..." (Joan Fisher Box quoted in \citet{pearl2018book})

\note{
The scientific consensus is like an ever changing conversation. 

Social science and government as connected conversations.
Social scientists working with humility and openness to convince themselves about mechanisms and laws (explanations). When many agree then we call it the "scientific consensus".  (Humility and openness means that we are not mostly trying to sell our favorite story about the world, but to learn about how the world works, to start by admitting that we don't understand everything, to search for and embrace lack of understanding.

Input to the conversation are attempts to persuade ourselves. Some contributions persuade more and some are easier to argue against. Are there guides to more or less persuasive contributions? (Yes. The creation of those guides is its own conversation and is the study of research design, methodology, statistics, philosophy and psychology).

We practice the design of persuasive research a lot in academia because we are all working to contribute to the consensus.

A growing movement in government aims to adapt the constant learning model from science to help manage the increasing speed of social, cultural, and economic and climate related change. So, more and more policy-experts are adding social science expertise --- in terms of both substance and methods of persuasive contribution.

I think that I am mostly trying to persuade myself rather than necessarily others. 
}

## Why not just talk about correlation and association?

Why the growing interest in *causal* inference rather than *population* inference or *measurement* inference?

My answer: Humanity needs a kind of engineering turn within part of the social sciences because of the growth in "How" questions: "How can we make government work better? How can we deliver development aid better?" 

Moving from "Why" to "How" involves the need to know about the effects of causes.

For examples of this move:  EGAP, J-PAL, Behavioral Insights teams, the
Evidence-Based Policy Movement, McKinsey, Deloitte and see \citep{bowerstesta2019epp}.

## What does ``cause'' mean?

When someone says ``$X$ causes $Y$'' they might mean:

\begin{description}
	\item[Persistent association]<1-> ``We always/mostly see $Y=1$ when $X=1$
		and $Y=0$ when $X=0$.''
	\item[Counterfactual Difference]<2-> ``If  $X$ had not been this value, then $Y$
		would not have been that value.''
	\item[Difference after manipulation]<3-> ``When we change $X$ from one
		value to another value, then $Y$ changes from one value to
		another value.'' (establishes causal
		priority of $X$ over $Y$, implied that $Y$ would not have changed.).
	\item[Difference after operation of a mechanism]<4-> ``Once upon a
		time $A$ changed $X$, and then one day $X$ changed $B$, and
		because of that $B$
		changed $C$, and finally $C$ changed $Y$.''
	\item[other\ldots]
\end{description}

## What does ``cause'' mean?

Often, \textbf{experiments} aim to \textbf{manipulate} (\textbf{by
randomization}) parts of
expected/theoretical mechanisms to reveal counter-factuals rather than aim to document persistent
and wide-spread association.

This week we will be focusing on the counterfactual approach because we focusing on experiments. It is not that we think it is wrong to _conceptualize_ "cause" in any other way. But that it has been productive to use the counterfactual approach.

\footnotesize{
\emph{Extra:} If you want to dig into this see \citet{brady2008cae}.
\url{http://egap.org/resources/guides/causality/}
}

## How to interpret "X causes Y"?

\begin{itemize}
 \item  "X causes Y" need not imply that W and V do not cause Y: X is a part of the story, not the whole story. (The whole story
is not necessary in order to learn about whether X causes Y).
  \item Counterfactual causation does not require "spatiotemporally continuous
   sequence of causal intermediates" ex: Person A plans event
Y. Person B's action would stop Y (say, a random bump from a stranger). Person
C doesn't know about Person A or action Y but stops B (maybe thinks B is going
to trip). So, Person A does action Y. And Person C causes action Y (without
Person C's action, Y would not have occurred).  \citep{holland:1986} 
 \item "X causes Y" requires a \textbf{context}: matches cause flame but require
   oxygen; small classrooms improve test scores but require experienced
teachers and funding \citep{cartwright2012evidence}.
\end{itemize}


## How to interpret "X causes Y"?

\begin{itemize}
\item   We can establish that X causes Y without knowing mechanism. The mechanism
    can be complex, it can involve probability: X causes Y sometimes because of
A and sometimes because of B. 
 \item "X causes Y" can mean "With X, probability of Y is higher than would be
   without X." or "Without X there is no Y." Either is compatible with the
counterfactual idea.
 \item Correlation is not causation: Favorite examples? 
 \item "X causes Y" is a statement about what didn't happen: "If X had not
   operated, occurred, then Y would not have occurred." (More about the
fundamental problem of counterfactual causation later)
\end{itemize}

# Randomization for Interpretable Comparisons and Clarity about Uncertainty

## Exercise: Observational studies vs. Randomized studies

**Discuss in small groups:**  Help me design the next project to answer
one of these questions (or one of your own causal questions). Just sketch the
key features of two designs --- one observational and the other randomized.

**Possible research questions:**

  - Can edutainment (like the Hausa TV Station or radio programs currently
    being used in Niger) change attitudes about violence and extermism?
    (Goal: Reduce violence and extremism.)
  - Does information about words spoken  to  infants/toddlers  improve early
    language aquisition in this group? (Goal:  reduce inequality in early verbal
    skills and eventually reducing inequality in school readiness at age 5)

## Exercise: Observational studies vs. Randomized studies

**Tasks:**

  1. Sketch an ideal observational study design? (no randomization, no
     researcher control but infinite resources for data collection) What
     questions would critical readers ask when you claim that your results
     reflect a causal relationship?

  2. Sketch an ideal experimental study design? (including randomization and
     control)  What questions would critical readers ask when you claim that
     your results reflect a causal relationship?

## Why randomize?

  1. Randomization produces \textbf{fair} comparisons (ex. impersonal, no
     systematic differences between groups).

  2. Randomization helps us reason about information/uncertainty. 

> "Fisher realized that an uncertain answer to the right question is much better than a highly certain answer to the wrong question...If you ask the right question, getting an answer that is occasionally wrong is much less of a problem [than answers to the wrong question]. You can still estimate the amount of uncertainty in your answer, because the uncertainty comes from the randomization procedure (which is known) rather than the characteristics of the soil (which are unknown)." \citep{pearl2018book}


## Using randomization to reason about causal \textcolor{orange}{Inference}

How can we use what we \textbf{see} to learn about \only<1>{what we want to
\textbf{know}} \only<2->{\textbf{potential outcomes} ($\text{causal effect}_i=f(y_{i,1},y_{i,0})$}?


```{r readdata, echo=FALSE}
newsdf <- read.csv("../Data/news.csv")
```

```{r setupnewsdesigntab,echo=FALSE}
newsdf$y1 <- ifelse(newsdf$z==1,newsdf$r,"?")
newsdf$y0 <- ifelse(newsdf$z==0,newsdf$r,"?")

library(xtable)

newspapers.xtab<-xtable(newsdf[,c("city","s","z","rpre","r","Newspaper","y1","y0")],
			label="tab:newspapers",
			caption="Design and outcomes in the Newspapers Experiment.
			The Treatment column shows treatment randomized
			within pair with the
			newspaper ads as 1 and lack of treatment as 0. The
			potential outcomes are $y_{1}$ for treatment and
			$y_{0}$ for control.  \\citet{pana2006}
			provides more detail on the design of the experiment.",
			align=c("l","l","c","c","c","c","c","c","c"))
```

```{r newsdesigntab,results='asis',echo=FALSE}
print(newspapers.xtab,
      sanitize.text.function=function(x){x},include.rownames=FALSE,include.colnames=FALSE,
      table.placement="!ht",size="small",
      comment=FALSE,
      add.to.row=list(pos=list(-1),
		      command="&&& \\multicolumn{2}{c}{Turnout} \\\\ City &
		      Pair & Treat & \\multicolumn{1}{c}{Baseline} &
		      \\multicolumn{1}{c}{Outcome} &
		      \\multicolumn{1}{c}{Newspaper} &
		      \\multicolumn{1}{c}{$y_{1}$} &
		      \\multicolumn{1}{c}{$y_{0}$}\\\\"),
      hline.after=c(0,nrow(newspapers.xtab)))
```

\only<3>{\textbf{\emph{Small group exercise:}} \textbf{Can you think of
		\textcolor{orange}{more than one way} to learn about the
		counterfactual causal effect of treatment using what we
		observe from an experiment?}}



Definition of a p-value. What does it mean?


## What is the true effect of the treatment assignment?

  \only<1>{
    \includegraphics[width=.8\textwidth]{cartoonNeymanBayesFisherCropped.pdf} }
  \only<2>{ \includegraphics[width=.8\textwidth]{cartoon3ATENeyman.pdf} }
  \only<3>{ \includegraphics[width=.8\textwidth]{cartoonBayes.pdf} }
  \only<4>{ \includegraphics[width=.8\textwidth]{cartoon4Fisher.pdf} }

\vfill

  \only<5->{See also \citet{pearl:2000a} and also
	  \cite{richardson2013single}. For more on the potential outcomes
	  approach see \cite{imbens2015causal}. }


## Estimating an Average Treatment Effect

```{r }
options(width=132)
```

```{r estate,echo=TRUE,results='markup',highlight=TRUE,tidy=FALSE,tidy.opts=list(width.cutoff=130)}
Z <- c(0,1,0,1)
Y <- c(16,22,7,14)
estate <- mean(Y[Z==1]) - mean(Y[Z==0]) ## same as coef(lm(Y~Z))["Z"]
estate
```



## Testing the Sharp Null of No Effects

```{r echo=FALSE}
options(width=132)
```

```{r sharpnulltest,echo=TRUE,results='markup',highlight=TRUE,tidy=FALSE,tidy.opts=list(width.cutoff=130)}
Om <- matrix(0,ncol=choose(4,2),nrow=length(Z)) ## All possible experiments
whotrted <- combn(1:4,2)
for(i in 1:choose(4,2)){ Om[cbind(whotrted[,i],i)]<-1 }
meandifftz <- function(y,z){ mean(y[z==1]) - mean(y[z==0]) }
thedist<-apply(Om,2, function(z){ meandifftz(Y,z) })
rbind(Om,thedist)
table(thedist)
theobs <- meandifftz(Y,Z)
mean(thedist >= theobs)
```

## What do we need to interpret our calculations as teaching about causal quantities?

\only<1->{For the sharp null test: Randomization occurred as
reported.}

\only<2->{For the average treatment effect: Randomization occurred
	as reported plus no interference between units.}


# Weaknesses of RCTs (To Discuss)

## Weaknesses of RCTs (To Discuss)

# References
