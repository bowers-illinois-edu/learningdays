---
title: Introducing Counterfactual Causal Inference
author: Jake Bowers and EGAP Learning Days Instructors
institute: University of Illinois @ Urbana-Champaign among other affiliations
bibliography: ../../Research-Group-Bibliography/big.bib
date: 8 April 2019 --- Bogot\'{a}
header-includes: \graphicspath{{.}{../images/}}
output:
  binb::metropolis:
    citation_package: natbib    
---

\newcommand{\bX}{\mathbf{X}}
\newcommand{\bZ}{\mathbf{Z}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}


```{r, include=FALSE}
options(tinytex.verbose = TRUE)
```


# What might `cause` **mean**?: Definitions and Conceptualization

## Some of my recent causal questions

Did \href{https://youtu.be/RgYIGLNdy9I}{a new Hausa television station} in
northern Nigeria change attitudes about violence, the role of women in
society, or the role of youth in society?

\only<2>{
\centering \includegraphics[width=.7\textwidth]{Arewa_pic1.png}}

Will adding education counselors to public housing in the USA increase the
numbers of low income youth enrolled in post-secondary education (like
university) and receiving financial aid for their education?

\only<3>{
\centering \includegraphics[width=.4\textwidth]{hudamps.pdf}}

Did the UKIP (anti-immigrant) party in the UK influence how individuals
\textbf{see} the ethnic characteristics of their communities?

\only<4>{
\centering \includegraphics[width=.5\textwidth]{beslondonmaps.pdf}}


## What are we doing when we talk about causation?

I think that we are trying **build evidence** for explanations.

Good evidence persuades --- it is harder to argue against.

Randomized experiments, we'll show, are especially persuasive about explanations involving **cause** in very focused ways. 

"[The experimenter's] aim is to draw valid conclusions of _determinate precision and generality_ from the evidence..." (Joan Fisher Box in Pearl's *Book of Why*). 

\note{
The scientific consensus is like an ever changing conversation. 

Social science and government as connected conversations.
Social scientists working with humility and openness to convince themselves about mechanisms and laws (explanations). When many agree then we call it the "scientific consensus".  (Humility and openness means that we are not mostly trying to sell our favorite story about the world, but to learn about how the world works, to start by admitting that we don't understand everything, to search for and embrace lack of understanding.

Input to the conversation are attempts to persuade ourselves. Some contributions persuade more and some are easier to argue against. Are there guides to more or less persuasive contributions? (Yes. The creation of those guides is its own conversation and is the study of research design, methodology, statistics, philosophy and psychology).

We practice the design of persuasive research a lot in academia because we are all working to contribute to the consensus.

A growing movement in government aims to adapt the constant learning model from science to help manage the increasing speed of social, cultural, and economic and climate related change. So, more and more policy-experts are adding social science expertise --- in terms of both substance and methods of persuasive contribution.

I think that I am mostly trying to persuade myself rather than necessarily others. 
}

## Why not just talk about correlation and association?

Why the growing interest in *causal* inference rather than *population* inference or *measurement* inference?

My answer: Humanity needs a kind of engineering turn within part of the social sciences. (like a doubling of the size of the social sciences, maintaining the same focus on theory and basic research but adding an engineering style branch).

Moving from "Why" to "How" involves the need to know about the effects of causes.

See the growth of EGAP, J-PAL, Behavioral Insights teams, the Evidence-Based Policy Movement, etc... 


## What does ``cause'' mean?

When someone says ``$X$ causes $Y$'' they might mean:

\begin{description}
	\item[Persistent association]<1-> ``We always/mostly see $Y=1$ when $X=1$
		and $Y=0$ when $X=0$.''
	\item[Counterfactual Difference]<2-> ``If  $X$ had not been this value, then $Y$
		would not have been that value.''
	\item[Difference after manipulation]<3-> ``When we change $X$ from one
		value to another value, then $Y$ changes from one value to
		another value.'' (establishes causal
		priority of $X$ over $Y$, implied that $Y$ would not have changed.).
	\item[Difference after operation of a mechanism]<4-> ``Once upon a
		time $A$ changed $X$, and then one day $X$ changed $B$, and
		because of that $B$
		changed $C$, and finally $C$ changed $Y$.''
	\item[other\ldots]
\end{description}

Often, \textbf{experiments} aim to \textbf{manipulate} (\textbf{by
randomization}) parts of
expected/theoretical mechanisms to reveal counter-factuals rather than aim to document persistent
and wide-spread association.

This week we will be focusing on the counterfactual approach because we focusing on experiments. It is not that we think it is wrong to _conceptualize_ "cause" in any other way. But that it has been productive to use the counterfactual approach.

\footnotesize{
\emph{Extra:} If you want to dig into this see \citet{brady2008cae}.
\url{http://egap.org/resources/guides/causality/}
}

## How to interpret "X causes Y"?

 -  "X causes Y" need not imply that W and V do not cause Y. "X causes Y" just
    means that X is a part of the story, not the whole story. (The whole story
is not necessary in order to learn about whether X causes Y).
 -  We can establish that X causes Y without knowing mechanism. The mechanism
    can be complex, it can involve probability: X causes Y sometimes because of
A and sometimes because of B. 
 - Counterfactual causation does not require "spatiotemporally continuous
   sequence of causal intermediates". \cite{holland:1986}: Person A plans event
Y. Person B's action would stop Y (say, a random bump from a stranger). Person
C doesn't know about Person A or action Y but stops B (maybe thinks B is going
to trip). So, Person A does action Y. And Person C causes action Y (without
Person C's action, Y would not have occurred). 
 - "X causes Y" can mean "With X, probability of Y is higher than would be
   without X." or "Without X there is no Y." Either is compatible with the
counterfactual idea.
 - Correlation is not causation: Favorite examples? 
 - "X causes Y" requires a \textbf{context}: matches cause flame but require
   oxygen; small classrooms improve test scores but require experienced
teachers and funding (Cartwright).
 - "X causes Y" is a statement about what didn't happen: "If X had not
   operated, occurred, then Y would not have occurred." (More about the
fundamental problem of counterfactual causation later)


# Randomization for Interpretable Comparisons and Clarity about Uncertainty

## Observational studies vs. Randomized studies

**Discuss in small groups:**  Help me design the next project to answer
one of these questions (or one of your own causal questions). Just sketch the
key features of two designs --- one observational and the other randomized.

**Possible research questions:**

  - Can edutainment (like the Hausa TV Station or radio programs currently being used in Niger) can change attitudes about violence and extermism?
  - Does telling low-SES parents about the number of words they speak to their infants and toddlers  improve early language aquisition in this group (reducing inequality in early verbal skills and eventually reducing inequality in school readiness at age 5)? 

**Tasks:**
  1. Sketch an ideal observational study design? (no
randomization, no researcher control but infinite resources for data
collection) What questions would critical readers ask when you claim that your
results reflect a causal relationship?
  2. Sketch an ideal experimental study design? (including
	randomization and control)  What questions would critical readers ask when you claim that your
	results reflect a causal relationship?

## Why randomize?

Randomization produces \textbf{fair} comparisons (ex. impersonal, no
systematic differences between groups).

Randomization helps us reason about information/uncertainty. 

> "Fisher realized that an uncertain answer to the right question is much better than a highly certain answer to the wrong question...If you ask the right question, getting an answer that is occasionally wrong is much less of a problem [than answers to the wrong question]. You can still estimate the amount of uncertainty in your answer, because the uncertainty comes from the randomization procedure (which is known) rather than the characteristics of the soil (which are unknown)." (Pearl, *book of why*)


# Overview of Statistical Inference for Causal Quantities

## Counterfactual Causal \textcolor{orange}{Inference}}

How can we use what we \textbf{see} to learn about \only<1>{what we want to
\textbf{know}} \only<2->{\textbf{potential outcomes} ($\text{causal effect}_i=f(y_{i,1},y_{i,0})$})?


```{r readdata, echo=FALSE}
newsdf <- read.csv("../Data/news.csv")
```

```{r setupnewsdesigntab,echo=FALSE}
newsdf$y1 <- ifelse(newsdf$z==1,newsdf$r,"?")
newsdf$y0 <- ifelse(newsdf$z==0,newsdf$r,"?")

library(xtable)

newspapers.xtab<-xtable(newsdf[,c("city","s","z","rpre","r","Newspaper","y1","y0")],
			label="tab:newspapers",
			caption="Design and outcomes in the Newspapers Experiment.
			The Treatment column shows treatment randomized
			within pair with the
			newspaper ads as 1 and lack of treatment as 0. The
			potential outcomes are $y_{1}$ for treatment and
			$y_{0}$ for control.  \\citet{pana2006}
			provides more detail on the design of the experiment.",
			align=c("l","l","c","c","c","c","c","c","c"))
```

```{r newsdesigntab,results='asis',echo=FALSE}
print(newspapers.xtab,
      sanitize.text.function=function(x){x},include.rownames=FALSE,include.colnames=FALSE,
      table.placement="!ht",##size="small",
      add.to.row=list(pos=list(-1),
		      command="&&& \\multicolumn{2}{c}{Turnout} \\\\ City &
		      Pair & Treatment & \\multicolumn{1}{c}{Baseline} &
		      \\multicolumn{1}{c}{Outcome} &
		      \\multicolumn{1}{c}{Newspaper} &
		      \\multicolumn{1}{c}{$y_{1}$} &
		      \\multicolumn{1}{c}{$y_{0}$}\\\\"),
      hline.after=c(0,nrow(newspapers.xtab)))
```

\only<3>{\textbf{\emph{Small group exercise:}} \textbf{Can you think of
		\textcolor{orange}{more than one way} to learn about the
		counterfactual causal effect of treatment using what we
		observe from an experiment?}}



Definition of a p-value. What does it mean?


## What is the true effect of the treatment assignment?}

  \only<1>{
    \includegraphics[width=.8\textwidth]{cartoonNeymanBayesFisherCropped.pdf} }
  \only<2>{ \includegraphics[width=.8\textwidth]{cartoon3ATENeyman.pdf} }
  \only<3>{ \includegraphics[width=.8\textwidth]{cartoonBayes.pdf} }
  \only<4>{ \includegraphics[width=.8\textwidth]{cartoon4Fisher.pdf} }

\vfill

  \only<5->{See also \citet{pearl:2000a} and also
	  \cite{richardson2013single}. For more on the potential outcomes
	  approach see \cite{imbens2015causal}. }


## Estimating an Average Treatment Effect}

```{r }
options(width=132)
```

```{r estate,echo=TRUE,results='markup',highlight=TRUE,tidy=FALSE,tidy.opts=list(width.cutoff=130)}
Z <- c(0,1,0,1)
Y <- c(16,22,7,14)
estate <- mean(Y[Z==1]) - mean(Y[Z==0]) ## same as coef(lm(Y~Z))["Z"]
estate
```



## Testing the Sharp Null of No Effects

```{r }
options(width=132)
```

```{r sharpnulltest,echo=TRUE,results='markup',highlight=TRUE,tidy=FALSE,tidy.opts=list(width.cutoff=130)}
Om <- matrix(0,ncol=choose(4,2),nrow=length(Z)) ## All possible experiments
whotrted <- combn(1:4,2)
for(i in 1:choose(4,2)){ Om[cbind(whotrted[,i],i)]<-1 }
meandifftz <- function(y,z){ mean(y[z==1]) - mean(y[z==0]) }
thedist<-apply(Om,2, function(z){ meandifftz(Y,z) })
rbind(Om,thedist)
table(thedist)
theobs <- meandifftz(Y,Z)
mean(thedist >= theobs)
```

## What do we need to interpret our calculations as teaching about causal quantities?

\only<1->{For the sharp null test: Randomization occurred as
reported.}

%% INCLUDE SLIDE FROM YALE TALK ON INTERFERENCE AND SHARP NULL

\medskip

\only<2->{For the average treatment effect: Randomization occurred
	as reported plus no interference between units.}


# Weaknesses of RCTs (To Discuss)

## Weaknesses of RCTs (To Discuss)

# References
