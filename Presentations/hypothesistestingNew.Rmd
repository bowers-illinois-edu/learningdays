---
title: What is a hypothesis test? Why test hypotheses?
author: Jake Bowers and EGAP Learning Days Instructors
institute: University of Illinois @ Urbana-Champaign among other affiliations
bibliography: ../../Research-Group-Bibliography/big.bib
date: 9 April 2019 --- Bogot√°
header-includes: \graphicspath{{.}{../images/}}
output:
  binb::metropolis:
    citation_package: natbib    
---

\newcommand{\bX}{\mathbf{X}}
\newcommand{\bZ}{\mathbf{Z}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}




```{r include=FALSE, cache=FALSE}
# Some customization.  You can alter or delete as desired (if you know what you are doing).
# knitr settings to control how R chunks work.
rm(list=ls())

require(knitr)

## This plus size="\\scriptsize" from https://stackoverflow.com/questions/26372138/beamer-presentation-rstudio-change-font-size-for-chunk

knitr::knit_hooks$set(mysize = function(before, options, envir) {
  if (before)
    return(options$size)
})

knit_hooks$set(plotdefault = function(before, options, envir) {
    if (before) par(mar = c(3, 3, .1, .1),oma=rep(0,4),mgp=c(1.5,.5,0))
})

opts_chunk$set(
  tidy=FALSE,     # display code as typed
  echo=TRUE,
  results='markup',
  strip.white=TRUE,
  fig.path='figs/fig',
  cache=FALSE,
  highlight=TRUE,
  width.cutoff=132,
  size='\\scriptsize',
  out.width='.8\\textwidth',
  fig.retina=FALSE,
  message=FALSE,
  comment=NA,
  mysize=TRUE,
  plotdefault=TRUE)

if(!file.exists('figs')) dir.create('figs')

options(digits=4,
	scipen=8,
	width=132
	)
```

# Overview

## Key Points for this lecture

Statistical inference (e.g. Hypothesis tests and confidence
intervals) is \textbf{inference} --- reasoning about the unobserved.

$p$-values require probability distributions.

\textcolor{blue}{Randomization} (or Design) +
\textcolor{orange}{a Hypothesis} + \textcolor{green}{a Test Statistic
Function} can provide
probability distributions representing the hypothesis (and thus
$p$-values).

## Using randomization to reason about causal \textcolor{orange}{Inference}

How can we use what we \textbf{see} to learn about \only<1>{what we want to
\textbf{know}} \only<2->{\textbf{potential outcomes} ($\text{causal effect}_i=f(y_{i,1},y_{i,0})$}?


```{r readdata, echo=FALSE}
newsdf <- read.csv("../Data/news.csv")
```

```{r setupnewsdesigntab,echo=FALSE}
newsdf$y1 <- ifelse(newsdf$z==1,newsdf$r,"?")
newsdf$y0 <- ifelse(newsdf$z==0,newsdf$r,"?")

library(xtable)

newspapers.xtab<-xtable(newsdf[,c("city","s","z","rpre","r","Newspaper","y1","y0")],
			label="tab:newspapers",
			caption="Design and outcomes in the Newspapers Experiment.
			The Treatment column shows treatment randomized
			within pair with the
			newspaper ads as 1 and lack of treatment as 0. The
			potential outcomes are $y_{1}$ for treatment and
			$y_{0}$ for control.  \\citet{pana2006}
			provides more detail on the design of the experiment.",
			align=c("l","l","c","c","c","c","c","c","c"))
```

```{r newsdesigntab,results='asis',echo=FALSE}
print(newspapers.xtab,
      sanitize.text.function=function(x){x},include.rownames=FALSE,include.colnames=FALSE,
      table.placement="!ht",size="small",
      comment=FALSE,
      add.to.row=list(pos=list(-1),
		      command="&&& \\multicolumn{2}{c}{Turnout} \\\\ City &
		      Pair & Treat & \\multicolumn{1}{c}{Baseline} &
		      \\multicolumn{1}{c}{Outcome} &
		      \\multicolumn{1}{c}{Newspaper} &
		      \\multicolumn{1}{c}{$y_{1}$} &
		      \\multicolumn{1}{c}{$y_{0}$}\\\\"),
      hline.after=c(0,nrow(newspapers.xtab)))
```

\only<3>{\textbf{\emph{Small group exercise:}} \textbf{Can you think of
		\textcolor{orange}{more than one way} to learn about the
		counterfactual causal effect of treatment using what we
		observe from an experiment?}}


## What is the true effect of the treatment assignment?

  \only<1>{
    \includegraphics[width=.8\textwidth]{cartoonNeymanBayesFisherCropped.pdf} }
  \only<2>{ \includegraphics[width=.8\textwidth]{cartoon3ATENeyman.pdf} }
  \only<3>{ \includegraphics[width=.8\textwidth]{cartoonBayes.pdf} }
  \only<4>{ \includegraphics[width=.8\textwidth]{cartoon4Fisher.pdf} }


## Ingredients of a hypothesis test

 - A **hypothesis** is a statement about a relationship among potential outcomes (Strong or Weak)
 - A **test statistic** summarizes the relationship between treatment and
   observed outcomes.
 - The **design** allows us to link the hypothesis and the test statistic:
   calculate a test statistic that describes a relationship between potential
   outcomes.
 - The **design** also generates a distribution of possible test statistics
   implied by the hypothesis
 - A $p$-value describes the relationship between our observed test statistic
   and the possible hypothesized test statistics


```{r setup, echo=FALSE}
library(randomizr)
library(coin)
```

```{r echo=FALSE}
## First, create some data, 
##  y0 is potential outcome to control
N <- 10
y0 <- c(0,0,0,1,1,3,4,5,190,200)
## Different individual level treatment effects
tau <- c(10,30,200,90,10,20,30,40,90,20)
## y1 is potential outcome to treatment
y1 <- y0 + tau
#sd(y0)
#mean(y1)-mean(y0)
# mean(tau)
## Z is treatment assignment
set.seed(12345)
Z <- complete_ra(N)
## Y is observed outcomes
Y <- Z*y1 + (1-Z)*y0
## The data
dat <- data.frame(Y=Y,Z=Z,y0=y0,tau=tau,y1=y1)
#dat
#pvalue(oneway_test(Y~factor(Z),data=dat,distribution=exact(),alternative="less"))
#pvalue(wilcox_test(Y~factor(Z),data=dat,distribution=exact(),alternative="less"))
```

## A hypothesis is a statement about or model of a relationship between potential outcomes

```{r}
kable(dat)
```

For example, the sharp, or strong, null hypothesis of no effects is $H_0: y_{i,1} = y_{i,0}$


## Test statistics summarize treatment to outcome relationships

```{r}
## The mean difference test statistic
meanTZ <- function(ys,z){ 
	mean(ys[z==1]) - mean(ys[z==0])
}

## The difference of mean ranks test statistic
meanrankTZ <- function(ys,z){
	ranky <- rank(ys)
	mean(ranky[z==1]) - mean(ranky[z==0])
}

observedMeanTZ <- meanTZ(ys=Y,z=Z)
observedMeanRankTZ <- meanrankTZ(ys=Y,z=Z)
observedMeanTZ
observedMeanRankTZ
```

## Linking test statistic and hypothesis.

What we observe for each person, $i$, ($Y_i$) is either what we would have
observed in treatment ($y_{i,1}$) **or** what we would have observed in
control ($y_{i,0}$).

$$Y_i = Z_i y_{i,1} + (1-Z_i)* y_{i,0}$$

So, if $y_{i,1}=y_{i,0}$ then:  $Y_i = y_{i,0}$: What we actually observe is
what we would have observed in the control condition.

## Generating the distribution of hypothetical test statistics

We need to know how to repeat our experiment:

```{r}
repeatExperiment <- function(N){
	complete_ra(N)
}
```

Then  we repeat it,  calculating the implied test statistic each time:

```{r reps, cache=TRUE}
set.seed(123456)
possibleMeanDiffsH0 <- replicate(10000,meanTZ(ys=Y,z=repeatExperiment(N=10)))
set.seed(123456)
possibleMeanRankDiffsH0 <- replicate(10000,meanrankTZ(ys=Y,z=repeatExperiment(N=10)))
```

## Plot the randomization distributions under the null

```{r fig.cap="An example of using the design of the experiment to test a hypothesis.", results='asis', echo=FALSE, fig.align='center'}
par(mfrow=c(1,2),mgp=c(1.5,.5,0),mar=c(3,3,0,0),oma=c(0,0,3,0))
plot(density(possibleMeanDiffsH0),
     ylim=c(0,.04),
     xlim=range(possibleMeanDiffsH0),
     lwd=2,
     main="",#Mean Difference Test Statistic",
     xlab="Mean Differences Consistent with H0")
rug(possibleMeanDiffsH0)
rug(observedMeanTZ,lwd=3,ticksize = .51)
text(observedMeanTZ-4,.022,"Observed Test Statistic")

plot(density(possibleMeanRankDiffsH0),lwd=2,
     ylim=c(0,.45),
     xlim=c(-10,10), #range(possibleMeanDiffsH0),
     main="", #Mean Difference of Ranks Test Statistic",
     xlab="Mean Difference of Ranks Consistent with H0")
rug(possibleMeanRankDiffsH0)
rug(observedMeanRankTZ,lwd=3,ticksize = .9)
text(observedMeanRankTZ,.45,"Observed Test Statistic")

mtext(side=3,outer=TRUE,text=expression(paste("Distributions of Test Statistics Consistent with the Design and ",H0: y[i1]==y[i0])))
```

## P-values summarize the plots

```{r calcpvalues}
pMeanTZ <- mean( possibleMeanDiffsH0 >= observedMeanTZ )
pMeanRankTZ <- mean( possibleMeanRankDiffsH0 >= observedMeanRankTZ )
pMeanTZ
pMeanRankTZ
```

## Next topics:

 - Testing weak null hypotheses $H_0: \bar{y}_{1} = \bar{y}_{0}$ 
 - Rejecting null hypotheses (and making false positive and/or false negative
   errors)
 - Power of hypothesis tests
 - Maintaining correct false positive error rates when testing more than one
   hypothesis. 


# References
